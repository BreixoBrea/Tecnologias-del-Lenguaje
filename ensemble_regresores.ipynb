{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Tecnolgías del Lenguaje. Entregable 4\n",
        "---\n",
        "#### Entrenamiento de modelos regresores con embeddings"
      ],
      "metadata": {
        "id": "C3ntO8xXSjpJ"
      },
      "id": "C3ntO8xXSjpJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook se entrenan y evalúan modelos de regresión para predecir los cinco rasgos de personalidad (Big Five) a partir de embeddings de posts de usuarios generados por modelos de lenguaje.\n",
        "\n",
        "La limpieza de datos es fundamental en este problema y no hay una solución óptima, por lo que utilizaremos los dos datasets de tipo \"top50\" generados con MPNet que recogen los 50 posts más relevantes para cada rasgo y de cada usuario, sin tener en cuenta la polaridad. Uno de los datasets tiene un umbral de 0.3, por lo que es menos restrictivo y tiene 140 000 filas, y el otro tiene un umbral de 0.4, por lo que es más restrictivo y tiene 40 000 filas. **No utilizaremos polaridad, aunque fue probado en una fase previa para los mismos regresores, pero obtuvimos resultados insatisfactorios.** Se utilizan tres tipos de regresores: **XGBoost**, **Random Forest** y **Ridge**, adaptando los hiperparámetros según el tamaño del dataset.\n",
        "\n",
        "En primer lugar, a partir de los conjuntos de datos mecionados, agrupamos los posts por usuario y calculamos un embedding por cada usuario que codifique su *body* de posts."
      ],
      "metadata": {
        "id": "J6NiG0gkYLWT"
      },
      "id": "J6NiG0gkYLWT"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e53e1c7b-8491-40ac-939f-5007a4a0975c",
      "metadata": {
        "id": "e53e1c7b-8491-40ac-939f-5007a4a0975c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56b5662-477d-4258-9d6c-12e38ec49c0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"cuda\")\n",
        "model.half() # reduce VRAM\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv(\"top50_posts_per_user_MPNet_by_trait_reduced.csv\")\n",
        "df_mt = pd.read_csv(\"top50_posts_per_user_MPNet_by_trait_reduced_more_threshold.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos los embeddings de los posts de cada usuario usando el mismo modelo de lenguaje (MPNet) que habíamos utilizado para reducir el dataset, normalizando los vectores para mejorar la comparabilidad. Primero, debemos generar embeddings post por post, y luego se agregan por usuario mediante un promedio de todos los embeddings de sus posts, obteniendo un vector único por usuario que representa su contenido textual."
      ],
      "metadata": {
        "id": "8XbUwh_KuXgR"
      },
      "id": "8XbUwh_KuXgR"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "90bf832d-662a-4397-890e-4fa7b32f110a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "0922c10082e64b888fcd09f8553976a7",
            "da9a34dd604a4cb69a78ca208986ebbe",
            "59e4c7a4d84948d48788170718f0959b",
            "acf25e94d46f46d4a8d6afc93b0d9a88",
            "f4a8ddc39b484351bb99589ac6a24f4d",
            "76344cea75a64c9487bda71d1ada3f52",
            "4bb5de86119541599f75e79da9d02494",
            "3b63e755ee9c4187ac68a7a48a0f9617",
            "179b1fa06cde4a3ea3596b7ea4520ad7",
            "0f4b74e6f33a4ed087f67ef920634510",
            "584de52dc9de467db3e62caae76258ed",
            "c706aa55abc342c7abe6fa976f5b325a",
            "d02a3f0c1c3f4b5283d02cc5fb3f9658",
            "d61c34e65b824b4d90b427d81ef9b343",
            "bc723446db9b4b78ab7fad47851ccbb3",
            "f01cde7aa80547069ed88daaf2510a2f",
            "43a3f2f72730440a9a558f323fc47b7a",
            "4817659ff2e94013be4d76cfe8558b85",
            "46abbb87aa5c4f6884582e0c4728b5ac",
            "19924670fdeb4a7d8c0568bd1653619b",
            "979b5a78310542f6ae7c2a6415f35eee",
            "df36c68782894d2da3ae9ff0da84dc9f"
          ]
        },
        "id": "90bf832d-662a-4397-890e-4fa7b32f110a",
        "outputId": "f59f1de0-7214-4a33-9d8d-c6dc55e436b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1097 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0922c10082e64b888fcd09f8553976a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/301 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c706aa55abc342c7abe6fa976f5b325a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensión del embedding por usuario: 768\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# Calcular embedding por post\n",
        "embeddings = model.encode(\n",
        "    df[\"post\"].tolist(),\n",
        "    batch_size=128,\n",
        "    show_progress_bar=True,\n",
        "    normalize_embeddings=True     # recomendado para MPNet\n",
        ")\n",
        "df[\"embedding\"] = list(embeddings)\n",
        "\n",
        "embeddings_mt = model.encode(df_mt[\"post\"].tolist(), batch_size=128, show_progress_bar=True, normalize_embeddings=True)\n",
        "df_mt[\"embedding\"] = list(embeddings_mt)\n",
        "\n",
        "# Calcular los embeddings por usuario\n",
        "user_embeddings = (\n",
        "    df.groupby(\"username\")[\"embedding\"]\n",
        "      .apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "user_embeddings_mt = (\n",
        "    df_mt.groupby(\"username\")[\"embedding\"]\n",
        "      .apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# Vector dimensionality\n",
        "embed_dim = len(user_embeddings[\"embedding\"].iloc[0])\n",
        "print(f\"Dimensión del embedding por usuario: {embed_dim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " La dimensión de los embeddings de usuario es 768, y servirá como input fijo para los modelos de regresión posteriores. Guardaremos los embeddings como .pkl para no tener que recalcularlos."
      ],
      "metadata": {
        "id": "obACR9MDsg-P"
      },
      "id": "obACR9MDsg-P"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar\n",
        "df.to_pickle(\"embeddings.pkl\")\n",
        "df_mt.to_pickle(\"embeddings_mt.pkl\")\n",
        "print(\"Embeddings guardados en embeddings.pkl y embeddings_mt.pkl\")\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QAVjvMhUTx-y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "081859ff-d2c0-424b-cb65-69b135b97e42"
      },
      "id": "QAVjvMhUTx-y",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings guardados en embeddings.pkl y embeddings_mt.pkl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      username              trait  \\\n",
              "0  -Areopagan-      Agreeableness   \n",
              "1  -Areopagan-      Agreeableness   \n",
              "2  -Areopagan-      Agreeableness   \n",
              "3  -Areopagan-           Openness   \n",
              "4  -Areopagan-  Conscientiousness   \n",
              "\n",
              "                                                post  similarity  \\\n",
              "0  I have two friends. I alienate everyone, event...    0.502757   \n",
              "1  I am smarter than you and will work you into d...    0.437536   \n",
              "2  Yeah I wouldnt want to deal with someone like ...    0.388882   \n",
              "3  I have two friends. I alienate everyone, event...    0.300504   \n",
              "4  I am smarter than you and will work you into d...    0.379553   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.04245, 0.02724, 0.006516, 0.036, -0.004215,...  \n",
              "1  [0.0235, 0.02602, -0.00786, -0.00944, 0.02873,...  \n",
              "2  [0.05643, 0.0437, 0.02481, -0.009125, -0.00469...  \n",
              "3  [0.04245, 0.02724, 0.006516, 0.036, -0.004215,...  \n",
              "4  [0.0235, 0.02602, -0.00786, -0.00944, 0.02873,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c206d86-2962-4550-b55a-adc3e9adde7a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>trait</th>\n",
              "      <th>post</th>\n",
              "      <th>similarity</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-Areopagan-</td>\n",
              "      <td>Agreeableness</td>\n",
              "      <td>I have two friends. I alienate everyone, event...</td>\n",
              "      <td>0.502757</td>\n",
              "      <td>[0.04245, 0.02724, 0.006516, 0.036, -0.004215,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-Areopagan-</td>\n",
              "      <td>Agreeableness</td>\n",
              "      <td>I am smarter than you and will work you into d...</td>\n",
              "      <td>0.437536</td>\n",
              "      <td>[0.0235, 0.02602, -0.00786, -0.00944, 0.02873,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-Areopagan-</td>\n",
              "      <td>Agreeableness</td>\n",
              "      <td>Yeah I wouldnt want to deal with someone like ...</td>\n",
              "      <td>0.388882</td>\n",
              "      <td>[0.05643, 0.0437, 0.02481, -0.009125, -0.00469...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-Areopagan-</td>\n",
              "      <td>Openness</td>\n",
              "      <td>I have two friends. I alienate everyone, event...</td>\n",
              "      <td>0.300504</td>\n",
              "      <td>[0.04245, 0.02724, 0.006516, 0.036, -0.004215,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-Areopagan-</td>\n",
              "      <td>Conscientiousness</td>\n",
              "      <td>I am smarter than you and will work you into d...</td>\n",
              "      <td>0.379553</td>\n",
              "      <td>[0.0235, 0.02602, -0.00786, -0.00944, 0.02873,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c206d86-2962-4550-b55a-adc3e9adde7a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c206d86-2962-4550-b55a-adc3e9adde7a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c206d86-2962-4550-b55a-adc3e9adde7a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3c8b8365-b649-4c82-80f7-ee8955799092\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c8b8365-b649-4c82-80f7-ee8955799092')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3c8b8365-b649-4c82-80f7-ee8955799092 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se cargan los embeddings previamente calculados desde archivos pickle y se convierten de listas a arrays de NumPy para facilitar su manipulación. Luego, los embeddings de usuario se expanden en columnas individuales, creando matrices donde cada columna representa una dimensión del embedding. Estas matrices deben ser transformadas en DataFrames de Pandas, con los nombres de columna indicativos (`emb_0`, `emb_1`, …) y se añaden los usernames correspondientes, dejando los DataFrames listos para usarse como features de entrada en los modelos de regresión."
      ],
      "metadata": {
        "id": "h-hzZEQZt8-y"
      },
      "id": "h-hzZEQZt8-y"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_pickle(\"embeddings.pkl\")\n",
        "df_mt = pd.read_pickle(\"embeddings_mt.pkl\")\n",
        "\n",
        "# Convertir listas a arrays numpy\n",
        "df[\"embedding\"] = df[\"embedding\"].apply(lambda x: np.array(x))\n",
        "df_mt[\"embedding\"] = df_mt[\"embedding\"].apply(lambda x: np.array(x))\n",
        "\n",
        "# Expandir el vector en columnas\n",
        "emb_matrix = np.vstack(user_embeddings[\"embedding\"].values)\n",
        "emb_matrix_mt = np.vstack(user_embeddings_mt[\"embedding\"].values)\n",
        "\n",
        "# Convertir los embeddings a un DataFrame de Pandas\n",
        "emb_df = pd.DataFrame(\n",
        "    emb_matrix,\n",
        "    columns=[f\"emb_{i}\" for i in range(embed_dim)]\n",
        ")\n",
        "emb_df_mt = pd.DataFrame(emb_matrix_mt, columns=[f\"emb_{i}\" for i in range(embed_dim)])\n",
        "\n",
        "# Añadir usernames\n",
        "emb_df[\"username\"] = user_embeddings[\"username\"].values\n",
        "emb_df_mt[\"username\"] = user_embeddings_mt[\"username\"].values"
      ],
      "metadata": {
        "id": "H0dJeuOFm3m4"
      },
      "id": "H0dJeuOFm3m4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargamos el *ground_truth*. Tiene pocos *missing_values*, por lo que imputaremos la media."
      ],
      "metadata": {
        "id": "5TeNypvMsqpv"
      },
      "id": "5TeNypvMsqpv"
    },
    {
      "cell_type": "code",
      "source": [
        "truth = pd.read_csv(\"authors_train.csv\")\n",
        "\n",
        "traits = [\n",
        "    \"agreeableness\",\n",
        "    \"openness\",\n",
        "    \"conscientiousness\",\n",
        "    \"extraversion\",\n",
        "    \"neuroticism\"\n",
        "]\n",
        "\n",
        "# Imputar la media por columna en los datos faltantes\n",
        "for col in traits:\n",
        "    mean_value = truth[col].mean()\n",
        "    truth[col].fillna(mean_value, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Z9UnGnmcK0",
        "outputId": "78ef2147-c73f-4b14-e4be-6c21723364fa"
      },
      "id": "76Z9UnGnmcK0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3295801460.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  truth[col].fillna(mean_value, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya podemos entrenar los modelos regresores para predecir los valores de los rasgos para cada autor. Utilizaremos las siguientes celdas para calcular un modelo por rasgo, para cada archivo (umbral 0.3 y umbral 0.4). Esto se repetirá para los modelos RandomForest, XGBoost y Ridge.\n",
        "\n",
        "#### **RandomForest (threshold = 0.3)**\n",
        "\n",
        "Para Random Forest se ajustan parámetros como profundidad máxima y número mínimo de muestras por hoja para mejorar estabilidad."
      ],
      "metadata": {
        "id": "A9iMQEgXu5vS"
      },
      "id": "A9iMQEgXu5vS"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "models = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Entrenando modelo para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings con truth\n",
        "    data = emb_df.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data.drop(columns=[\"username\", t])\n",
        "    y = data[t]\n",
        "\n",
        "    # Split train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Random Forest optimizado\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=700,           # más árboles para mayor precisión\n",
        "        max_depth=18,               # limita profundidad para reducir overfitting\n",
        "        min_samples_leaf=3,         # evita splits con muy pocos datos\n",
        "        max_features=0.4,           # 40% de features por split, útil con embeddings densos\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        bootstrap=True\n",
        "    )\n",
        "\n",
        "    # Entrenar\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "    print(f\"MSE: {mse:.2f}  |  MAE: {mae:.2f}  |  R²: {r2:.4f}  |  Pearson: {pearson_corr:.4f}\")\n",
        "\n",
        "    models[t] = model\n",
        "\n",
        "\n",
        "# Guardar modelos\n",
        "for trait, model in models.items():\n",
        "    with open(f\"rf_embeddings_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nModelos guardados como rf_embeddings_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ErGEKrNZ_tx",
        "outputId": "701b7af0-645f-4115-d2ee-8a6b94148e86"
      },
      "id": "5ErGEKrNZ_tx",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo para agreeableness ===\n",
            "MSE: 881.66  |  MAE: 25.91  |  R²: 0.0314  |  Pearson: 0.2067\n",
            "\n",
            "=== Entrenando modelo para openness ===\n",
            "MSE: 793.32  |  MAE: 23.90  |  R²: 0.0395  |  Pearson: 0.2014\n",
            "\n",
            "=== Entrenando modelo para conscientiousness ===\n",
            "MSE: 856.58  |  MAE: 25.53  |  R²: -0.0043  |  Pearson: 0.1196\n",
            "\n",
            "=== Entrenando modelo para extraversion ===\n",
            "MSE: 1032.45  |  MAE: 28.38  |  R²: 0.0599  |  Pearson: 0.2479\n",
            "\n",
            "=== Entrenando modelo para neuroticism ===\n",
            "MSE: 914.60  |  MAE: 26.57  |  R²: 0.0961  |  Pearson: 0.3422\n",
            "\n",
            "Modelos guardados como rf_embeddings_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **RandomForest (threhold = 0.4)**"
      ],
      "metadata": {
        "id": "KoVe0FpLwK1v"
      },
      "id": "KoVe0FpLwK1v"
    },
    {
      "cell_type": "code",
      "source": [
        "models_mt = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Entrenando modelo para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings con truth\n",
        "    data_mt = emb_df_mt.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data_mt.drop(columns=[\"username\", t])\n",
        "    y = data_mt[t]\n",
        "\n",
        "    # Split train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Random Forest optimizado para 40k filas\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=500,       # suficiente para estabilidad\n",
        "        max_depth=15,           # limita profundidad para evitar overfitting\n",
        "        min_samples_leaf=4,     # evita splits con muy pocos datos\n",
        "        max_features=0.3,       # 30% de features por split\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        bootstrap=True\n",
        "    )\n",
        "\n",
        "    # Entrenar\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predicciones\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "    print(f\"MSE: {mse:.2f}  |  MAE: {mae:.2f}  |  R²: {r2:.4f}  |  Pearson: {pearson_corr:.4f}\")\n",
        "\n",
        "    models_mt[t] = model\n",
        "\n",
        "\n",
        "# Guardar modelos\n",
        "for trait, model in models_mt.items():\n",
        "    with open(f\"rf_embeddings_mt_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nModelos guardados como rf_embeddings_mt_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9XRf9DLbJE7",
        "outputId": "7656cada-6673-4968-969b-e7280912c6d3"
      },
      "id": "u9XRf9DLbJE7",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo para agreeableness ===\n",
            "MSE: 853.24  |  MAE: 25.48  |  R²: 0.0628  |  Pearson: 0.2957\n",
            "\n",
            "=== Entrenando modelo para openness ===\n",
            "MSE: 718.48  |  MAE: 22.32  |  R²: 0.0101  |  Pearson: 0.1520\n",
            "\n",
            "=== Entrenando modelo para conscientiousness ===\n",
            "MSE: 815.74  |  MAE: 24.13  |  R²: 0.0679  |  Pearson: 0.2703\n",
            "\n",
            "=== Entrenando modelo para extraversion ===\n",
            "MSE: 899.90  |  MAE: 26.45  |  R²: 0.0258  |  Pearson: 0.2120\n",
            "\n",
            "=== Entrenando modelo para neuroticism ===\n",
            "MSE: 1062.17  |  MAE: 28.95  |  R²: 0.0224  |  Pearson: 0.1857\n",
            "\n",
            "Modelos guardados como rf_embeddings_mt_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **XGBoost (threshold = 0.3)**\n",
        "\n",
        "Para XGBoost se emplea early stopping sobre un conjunto de validación para optimizar la cantidad de árboles y evitar sobreajuste"
      ],
      "metadata": {
        "id": "CqpomvCcwSWO"
      },
      "id": "CqpomvCcwSWO"
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "models = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Entrenando modelo para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings con el truth\n",
        "    data = emb_df_mt.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data.drop(columns=[\"username\", t])\n",
        "    y = data[t]\n",
        "\n",
        "    # Split Train + Test\n",
        "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Split Train_full → Train + Val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_full, y_train_full,\n",
        "        test_size=0.1,  # 10% del train_full → ~8% total\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Convertir a DMatrix (XGBoost nativo)\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Parámetros\n",
        "    params = {\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        \"learning_rate\": 0.015,\n",
        "        \"max_depth\": 4,\n",
        "        \"min_child_weight\": 8,\n",
        "        \"subsample\": 0.8,\n",
        "        \"colsample_bytree\": 0.25,\n",
        "        \"colsample_bylevel\": 0.25,\n",
        "        \"reg_alpha\": 1.0,\n",
        "        \"reg_lambda\": 2.0,\n",
        "        \"eval_metric\": \"rmse\",\n",
        "        \"seed\": 42\n",
        "    }\n",
        "\n",
        "    # Entrenar con early stopping usando la validación\n",
        "    evallist = [(dtrain, \"train\"), (dval, \"eval\")]\n",
        "\n",
        "    bst = xgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=1200,\n",
        "        evals=evallist,\n",
        "        early_stopping_rounds=50,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # Predicciones para test\n",
        "    preds = bst.predict(dtest)\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "    print(f\"MSE: {mse:.2f}  |  MAE: {mae:.2f}  |  R²: {r2:.4f}  |  Pearson: {pearson_corr:.4f}\")\n",
        "\n",
        "    models[t] = bst\n",
        "\n",
        "# Guardar modelos\n",
        "for trait, model in models.items():\n",
        "    with open(f\"xgb_embeddings_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nModelos guardados como xgb_embeddings_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHyggx3oa0rK",
        "outputId": "7dc4c17e-1e21-4cb7-de29-278f32b788c6"
      },
      "id": "ZHyggx3oa0rK",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo para agreeableness ===\n",
            "MSE: 860.14  |  MAE: 25.69  |  R²: 0.0552  |  Pearson: 0.2731\n",
            "\n",
            "=== Entrenando modelo para openness ===\n",
            "MSE: 710.26  |  MAE: 22.03  |  R²: 0.0214  |  Pearson: 0.1548\n",
            "\n",
            "=== Entrenando modelo para conscientiousness ===\n",
            "MSE: 809.69  |  MAE: 24.30  |  R²: 0.0748  |  Pearson: 0.2866\n",
            "\n",
            "=== Entrenando modelo para extraversion ===\n",
            "MSE: 895.46  |  MAE: 26.27  |  R²: 0.0306  |  Pearson: 0.2008\n",
            "\n",
            "=== Entrenando modelo para neuroticism ===\n",
            "MSE: 1096.31  |  MAE: 29.13  |  R²: -0.0090  |  Pearson: 0.1333\n",
            "\n",
            "Modelos guardados como xgb_embeddings_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **XGBoost (threshold = 0.4)**"
      ],
      "metadata": {
        "id": "fcWcrbZHwuCu"
      },
      "id": "fcWcrbZHwuCu"
    },
    {
      "cell_type": "code",
      "source": [
        "models_mt = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Entrenando modelo para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings con el truth\n",
        "    data_mt = emb_df_mt.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data_mt.drop(columns=[\"username\", t])\n",
        "    y = data_mt[t]\n",
        "\n",
        "    # Split Train + Test\n",
        "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Split Train_full → Train + Val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_full, y_train_full,\n",
        "        test_size=0.1,  # 10% del train_full → ~8% total\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Convertir a DMatrix\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dval = xgb.DMatrix(X_val, label=y_val)\n",
        "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "    # Parámetros\n",
        "    params = {\n",
        "        \"objective\": \"reg:squarederror\",\n",
        "        \"learning_rate\": 0.015,\n",
        "        \"max_depth\": 3,\n",
        "        \"min_child_weight\": 12,\n",
        "        \"subsample\": 0.8,\n",
        "        \"colsample_bytree\": 0.2,\n",
        "        \"colsample_bylevel\": 0.25,\n",
        "        \"reg_alpha\": 2.0,\n",
        "        \"reg_lambda\": 3.0,\n",
        "        \"eval_metric\": \"rmse\",\n",
        "        \"seed\": 42\n",
        "    }\n",
        "\n",
        "    evallist = [(dtrain, \"train\"), (dval, \"eval\")]\n",
        "\n",
        "    # Entrenar con early stopping usando la validación\n",
        "    bst = xgb.train(\n",
        "        params,\n",
        "        dtrain,\n",
        "        num_boost_round=800,\n",
        "        evals=evallist,\n",
        "        early_stopping_rounds=50,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "\n",
        "    # Predicciones para test\n",
        "    preds = bst.predict(dtest)\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "    print(f\"MSE: {mse:.2f}  |  MAE: {mae:.2f}  |  R²: {r2:.4f}  |  Pearson: {pearson_corr:.4f}\")\n",
        "\n",
        "    models_mt[t] = bst\n",
        "\n",
        "# Guardar modelos\n",
        "for trait, model in models.items():\n",
        "    with open(f\"xgb_embeddings_mt_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nModelos guardados como xgb_embeddings_mt_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHkstytbdF1-",
        "outputId": "9864f58c-c9b6-4867-8c47-91816e95d593"
      },
      "id": "FHkstytbdF1-",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Entrenando modelo para agreeableness ===\n",
            "MSE: 877.51  |  MAE: 26.01  |  R²: 0.0361  |  Pearson: 0.2224\n",
            "\n",
            "=== Entrenando modelo para openness ===\n",
            "MSE: 705.47  |  MAE: 21.99  |  R²: 0.0280  |  Pearson: 0.1685\n",
            "\n",
            "=== Entrenando modelo para conscientiousness ===\n",
            "MSE: 820.26  |  MAE: 24.37  |  R²: 0.0627  |  Pearson: 0.2560\n",
            "\n",
            "=== Entrenando modelo para extraversion ===\n",
            "MSE: 880.47  |  MAE: 26.08  |  R²: 0.0468  |  Pearson: 0.2397\n",
            "\n",
            "=== Entrenando modelo para neuroticism ===\n",
            "MSE: 1089.06  |  MAE: 29.03  |  R²: -0.0023  |  Pearson: 0.1324\n",
            "\n",
            "Modelos guardados como xgb_embeddings_mt_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ridge (threshold = 0.3)\n",
        "\n",
        "Para Ridge se realiza una búsqueda en un grid de valores de alpha para minimizar el RMSE."
      ],
      "metadata": {
        "id": "ljZtV1sxw4M_"
      },
      "id": "ljZtV1sxw4M_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Grid de alpha para probar\n",
        "alpha_grid = np.logspace(-3, 3, 100)  # 0.001 a 1000, 100 valores\n",
        "\n",
        "models = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Selección de mejor Ridge para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings y truth\n",
        "    data = emb_df.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data.drop(columns=[\"username\", t])\n",
        "    y = data[t]\n",
        "\n",
        "    # Dividir dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    best_mse = np.inf\n",
        "    best_model = None\n",
        "    best_metrics = {}\n",
        "\n",
        "    for alpha in alpha_grid:\n",
        "        model = Ridge(alpha=alpha, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        # Calcular métricas\n",
        "        mse = mean_squared_error(y_test, preds)\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        r2 = r2_score(y_test, preds)\n",
        "        pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "        # Selección del mejor modelo por RMSE\n",
        "        if mse < best_mse:\n",
        "            best_rmse = mse\n",
        "            best_model = model\n",
        "            best_metrics = {\"MSE\": mse, \"MAE\": mae, \"R2\": r2, \"Pearson\": pearson_corr}\n",
        "\n",
        "    print(f\"MSE: {best_metrics['MSE']:.2f}  |  MAE: {best_metrics['MAE']:.2f}  |  R²: {best_metrics['R2']:.4f}  |  Pearson: {best_metrics['Pearson']:.4f}\")\n",
        "    models[t] = best_model\n",
        "\n",
        "# Guardar los mejores modelos por rasgo\n",
        "for trait, model in models.items():\n",
        "    with open(f\"best_ridge_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nMejores modelos Ridge guardados como best_ridge_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIFevIO8Mvx",
        "outputId": "0b497821-349f-4504-a0e3-47e9d2ee507b"
      },
      "id": "GNIFevIO8Mvx",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Selección de mejor Ridge para agreeableness ===\n",
            "MSE: 915.44  |  MAE: 26.57  |  R²: -0.0057  |  Pearson: 0.1135\n",
            "\n",
            "=== Selección de mejor Ridge para openness ===\n",
            "MSE: 826.98  |  MAE: 24.16  |  R²: -0.0013  |  Pearson: 0.1173\n",
            "\n",
            "=== Selección de mejor Ridge para conscientiousness ===\n",
            "MSE: 856.89  |  MAE: 25.66  |  R²: -0.0046  |  Pearson: 0.1825\n",
            "\n",
            "=== Selección de mejor Ridge para extraversion ===\n",
            "MSE: 1099.42  |  MAE: 29.33  |  R²: -0.0011  |  Pearson: 0.0683\n",
            "\n",
            "=== Selección de mejor Ridge para neuroticism ===\n",
            "MSE: 1012.47  |  MAE: 28.12  |  R²: -0.0006  |  Pearson: 0.1664\n",
            "\n",
            "Mejores modelos Ridge guardados como best_ridge_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ridge (threshold = 0.4)"
      ],
      "metadata": {
        "id": "wQbtWyWXxDQV"
      },
      "id": "wQbtWyWXxDQV"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "models_mt = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Selección de mejor Ridge para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings y truth\n",
        "    data_mt = emb_df_mt.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data_mt.drop(columns=[\"username\", t])\n",
        "    y = data_mt[t]\n",
        "\n",
        "    # Dividir dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    best_mse = np.inf\n",
        "    best_model = None\n",
        "    best_metrics = {}\n",
        "\n",
        "    for alpha in alpha_grid:\n",
        "        model = Ridge(alpha=alpha, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        # Calcular métricas\n",
        "        mse = mean_squared_error(y_test, preds)\n",
        "        mae = mean_absolute_error(y_test, preds)\n",
        "        r2 = r2_score(y_test, preds)\n",
        "        pearson_corr, _ = pearsonr(y_test, preds)\n",
        "\n",
        "        # Selección del mejor modelo por RMSE\n",
        "        if mse < best_mse:\n",
        "            best_mse = mse\n",
        "            best_model = model\n",
        "            best_metrics = {\"MSE\": mse, \"MAE\": mae, \"R2\": r2, \"Pearson\": pearson_corr}\n",
        "\n",
        "    print(f\"MSE: {best_metrics['MSE']:.2f}  |  MAE: {best_metrics['MAE']:.2f}  |  R²: {best_metrics['R2']:.4f}  |  Pearson: {best_metrics['Pearson']:.4f}\")\n",
        "    models_mt[t] = best_model\n",
        "\n",
        "# Guardar los mejores modelos por rasgo\n",
        "for trait, model in models_mt.items():\n",
        "    with open(f\"best_ridge_mt_{trait}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "print(\"\\nMejores modelos Ridge guardados como best_ridge_mt_[trait].pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AB0plOxkVhk",
        "outputId": "9d4f11e9-7496-408a-d987-61860bc14b62"
      },
      "id": "1AB0plOxkVhk",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Selección de mejor Ridge para agreeableness ===\n",
            "MSE: 870.68  |  MAE: 25.72  |  R²: 0.0436  |  Pearson: 0.2371\n",
            "\n",
            "=== Selección de mejor Ridge para openness ===\n",
            "MSE: 715.44  |  MAE: 22.18  |  R²: 0.0143  |  Pearson: 0.1245\n",
            "\n",
            "=== Selección de mejor Ridge para conscientiousness ===\n",
            "MSE: 828.42  |  MAE: 24.40  |  R²: 0.0534  |  Pearson: 0.2334\n",
            "\n",
            "=== Selección de mejor Ridge para extraversion ===\n",
            "MSE: 916.27  |  MAE: 26.73  |  R²: 0.0081  |  Pearson: 0.1375\n",
            "\n",
            "=== Selección de mejor Ridge para neuroticism ===\n",
            "MSE: 1084.90  |  MAE: 29.04  |  R²: 0.0015  |  Pearson: 0.1075\n",
            "\n",
            "Mejores modelos Ridge guardados como best_ridge_mt_[trait].pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Baseline utilizando la media y desviación.**\n",
        "\n",
        "La predicción se basa únicamente en la media del rasgo en el conjunto de entrenamiento, a la que se añade una pequeña variación aleatoria proporcional a la desviación estándar, simulando ligeras oscilaciones sin usar ninguna información de los embeddings. Calculamos las mismas métricas de desempeño (MSE, MAE, R² y correlación de Pearson) sobre el conjunto de test para tener un punto de referencia."
      ],
      "metadata": {
        "id": "Z4UTyDwmxFFw"
      },
      "id": "Z4UTyDwmxFFw"
    },
    {
      "cell_type": "code",
      "source": [
        "models_baseline = {}\n",
        "\n",
        "for t in traits:\n",
        "    print(f\"\\n=== Modelo baseline conservador para {t} ===\")\n",
        "\n",
        "    # Fusionar embeddings y truth\n",
        "    data = emb_df.merge(truth[[\"username\", t]], on=\"username\")\n",
        "\n",
        "    X = data.drop(columns=[\"username\", t])\n",
        "    y = data[t]\n",
        "\n",
        "    # Dividir dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Media y desviación estándar del rasgo en train\n",
        "    mean_y = y_train.mean()\n",
        "    std_y = y_train.std()\n",
        "\n",
        "    # Predicción: media + pequeña variación aleatoria\n",
        "    np.random.seed(42)\n",
        "    small_factor = 0.05  # porcentaje de oscilación respecto a std\n",
        "    preds = mean_y + np.random.normal(0, std_y * small_factor, size=len(y_test))\n",
        "\n",
        "    # Métricas\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    pearson_corr, p_value = pearsonr(y_test, preds)\n",
        "\n",
        "    print(f\"MSE: {mse:.2f}  |  MAE: {mae:.2f}  |  R²: {r2:.4f}  |  Pearson: {pearson_corr:.4f}\")\n",
        "\n",
        "    # Guardar modelo (solo media y factor de variación)\n",
        "    models_baseline[t] = {\"mean\": mean_y, \"small_factor\": small_factor}\n",
        "\n",
        "# Guardar modelos baseline\n",
        "with open(\"baseline_mean_variation_models.pkl\", \"wb\") as f:\n",
        "    pickle.dump(models_baseline, f)\n",
        "\n",
        "print(\"\\nModelos baseline guardados como baseline_mean_variation_models.pkl\")\n"
      ],
      "metadata": {
        "id": "Tqnvg5sFOIjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1645c7da-449d-4415-f481-d49e6a02ca2d"
      },
      "id": "Tqnvg5sFOIjP",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Modelo baseline conservador para agreeableness ===\n",
            "MSE: 921.45  |  MAE: 26.67  |  R²: -0.0123  |  Pearson: -0.0377\n",
            "\n",
            "=== Modelo baseline conservador para openness ===\n",
            "MSE: 830.19  |  MAE: 24.21  |  R²: -0.0052  |  Pearson: -0.0137\n",
            "\n",
            "=== Modelo baseline conservador para conscientiousness ===\n",
            "MSE: 858.63  |  MAE: 25.68  |  R²: -0.0067  |  Pearson: 0.0084\n",
            "\n",
            "=== Modelo baseline conservador para extraversion ===\n",
            "MSE: 1096.99  |  MAE: 29.23  |  R²: 0.0011  |  Pearson: 0.0522\n",
            "\n",
            "=== Modelo baseline conservador para neuroticism ===\n",
            "MSE: 1020.97  |  MAE: 28.22  |  R²: -0.0090  |  Pearson: -0.0563\n",
            "\n",
            "Modelos baseline guardados como baseline_mean_variation_models.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ensemble de modelos**\n",
        "\n",
        "En base a los resultados anteriores, guardamos los mejores modelos por rasgo para calcular un ensemble."
      ],
      "metadata": {
        "id": "ig7xahoH1jHC"
      },
      "id": "ig7xahoH1jHC"
    },
    {
      "cell_type": "code",
      "source": [
        "model_paths = {\n",
        "    \"agreeableness\": \"rf_embeddings_mt_agreeableness.pkl\",\n",
        "    \"openness\": \"xgb_embeddings_mt_openness.pkl\",\n",
        "    \"conscientiousness\": \"xgb_embeddings_conscientiousness.pkl\",\n",
        "    \"extraversion\": \"xgb_embeddings_mt_extraversion.pkl\",\n",
        "    \"neuroticism\": \"rf_embeddings_neuroticism.pkl\",\n",
        "}\n",
        "\n",
        "models_ensemble = {}\n",
        "\n",
        "for trait, path in model_paths.items():\n",
        "    with open(path, \"rb\") as f:\n",
        "        models_ensemble[trait] = pickle.load(f)\n",
        "\n",
        "print(\"Modelos cargados para el ensemble.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjuSvmuk1jh2",
        "outputId": "3a0bfa91-5440-4034-9ed7-451b409bbd5c"
      },
      "id": "WjuSvmuk1jh2",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelos cargados para el ensemble.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predicción**"
      ],
      "metadata": {
        "id": "kH-M8OaxrNiy"
      },
      "id": "kH-M8OaxrNiy"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "# -----------------------------\n",
        "# Archivos de entrada (por rasgo)\n",
        "# -----------------------------\n",
        "embedding_files = {\n",
        "    \"agreeableness\": \"embeddings_mt.pkl\",\n",
        "    \"openness\": \"embeddings_mt.pkl\",\n",
        "    \"conscientiousness\": \"embeddings.pkl\",\n",
        "    \"extraversion\": \"embeddings_mt.pkl\",\n",
        "    \"neuroticism\": \"embeddings.pkl\"\n",
        "}\n",
        "\n",
        "# -----------------------------\n",
        "# Modelos del ensemble\n",
        "# -----------------------------\n",
        "model_paths = {\n",
        "    \"agreeableness\": \"rf_embeddings_mt_agreeableness.pkl\",\n",
        "    \"openness\": \"xgb_embeddings_mt_openness.pkl\",\n",
        "    \"conscientiousness\": \"xgb_embeddings_conscientiousness.pkl\",\n",
        "    \"extraversion\": \"xgb_embeddings_mt_extraversion.pkl\",\n",
        "    \"neuroticism\": \"rf_embeddings_neuroticism.pkl\"\n",
        "}\n",
        "\n",
        "traits = list(model_paths.keys())\n",
        "\n",
        "authors_test_file = \"authors_test.csv\"\n",
        "output_file = \"predicciones_ensemble_BSP.csv\"\n",
        "\n",
        "# -----------------------------\n",
        "# Cargar lista completa de autores de test\n",
        "# -----------------------------\n",
        "authors_test = pd.read_csv(authors_test_file)  # columna 'username'\n",
        "\n",
        "# -----------------------------\n",
        "# Preparar dataframe final\n",
        "# -----------------------------\n",
        "predictions = authors_test[[\"username\"]].copy()\n",
        "\n",
        "# =============================\n",
        "#   PREDICCIÓN POR CADA RASGO\n",
        "# =============================\n",
        "\n",
        "for trait in traits:\n",
        "    print(f\"\\n=== Procesando {trait.upper()} ===\")\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 1. Cargar embeddings correctos para el rasgo\n",
        "    # --------------------------------------\n",
        "    emb_file = embedding_files[trait]\n",
        "    print(f\"Usando embeddings: {emb_file}\")\n",
        "    df = pd.read_pickle(emb_file)\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 2. Agregar embeddings por usuario\n",
        "    # --------------------------------------\n",
        "    user_embeddings = (\n",
        "        df.groupby(\"username\")[\"embedding\"]\n",
        "          .apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
        "          .reset_index()\n",
        "    )\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 3. Merge con autores de test (mantener orden + usuarios sin embedding)\n",
        "    # --------------------------------------\n",
        "    user_embeddings = authors_test[[\"username\"]].merge(\n",
        "        user_embeddings, on=\"username\", how=\"left\"\n",
        "    )\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 4. Rellenar embeddings faltantes\n",
        "    # --------------------------------------\n",
        "    embedding_mean = np.mean(\n",
        "        np.vstack(user_embeddings[\"embedding\"].dropna().values), axis=0\n",
        "    )\n",
        "\n",
        "    user_embeddings[\"embedding\"] = user_embeddings[\"embedding\"].apply(\n",
        "        lambda x: x if isinstance(x, np.ndarray) else embedding_mean\n",
        "    )\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 5. Convertir a DataFrame con nombres de columnas\n",
        "    # --------------------------------------\n",
        "    embed_dim = len(user_embeddings[\"embedding\"].iloc[0])\n",
        "    X_test = pd.DataFrame(\n",
        "        np.vstack(user_embeddings[\"embedding\"].values),\n",
        "        columns=[f\"emb_{i}\" for i in range(embed_dim)]\n",
        "    )\n",
        "\n",
        "    feature_names = list(X_test.columns)\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 6. Cargar modelo correcto para el rasgo\n",
        "    # --------------------------------------\n",
        "    with open(model_paths[trait], \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # --------------------------------------\n",
        "    # 7. Predicción\n",
        "    # --------------------------------------\n",
        "    if \"xgboost\" in str(type(model)).lower():\n",
        "        # XGBoost → necesita DMatrix\n",
        "        dtest = xgb.DMatrix(X_test, feature_names=feature_names)\n",
        "        y_pred = model.predict(dtest)\n",
        "    else:\n",
        "        # RandomForest → usa DataFrame directamente\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    predictions[trait] = y_pred\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Añadir columnas fijas y reordenar\n",
        "# -----------------------------\n",
        "predictions[\"team_name\"] = \"BSP\"\n",
        "predictions[\"variant_name\"] = \"ensemble_best_per_trait\"\n",
        "\n",
        "predictions = predictions[\n",
        "    [\"team_name\", \"variant_name\", \"username\"] + traits\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Guardar CSV final\n",
        "# -----------------------------\n",
        "predictions.to_csv(output_file, index=False)\n",
        "print(f\"\\nArchivo de predicciones generado: {output_file} ({len(predictions)} autores)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAsPtgYs3-35",
        "outputId": "bc855e0c-e0c6-495d-fd7c-8bf8bba03e92"
      },
      "id": "KAsPtgYs3-35",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Procesando AGREEABLENESS ===\n",
            "Usando embeddings: embeddings_mt.pkl\n",
            "\n",
            "=== Procesando OPENNESS ===\n",
            "Usando embeddings: embeddings_mt.pkl\n",
            "\n",
            "=== Procesando CONSCIENTIOUSNESS ===\n",
            "Usando embeddings: embeddings.pkl\n",
            "\n",
            "=== Procesando EXTRAVERSION ===\n",
            "Usando embeddings: embeddings_mt.pkl\n",
            "\n",
            "=== Procesando NEUROTICISM ===\n",
            "Usando embeddings: embeddings.pkl\n",
            "\n",
            "Archivo de predicciones generado: predicciones_ensemble_BSP.csv (323 autores)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5be08yX2PwJ"
      },
      "id": "N5be08yX2PwJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0922c10082e64b888fcd09f8553976a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da9a34dd604a4cb69a78ca208986ebbe",
              "IPY_MODEL_59e4c7a4d84948d48788170718f0959b",
              "IPY_MODEL_acf25e94d46f46d4a8d6afc93b0d9a88"
            ],
            "layout": "IPY_MODEL_f4a8ddc39b484351bb99589ac6a24f4d"
          }
        },
        "da9a34dd604a4cb69a78ca208986ebbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76344cea75a64c9487bda71d1ada3f52",
            "placeholder": "​",
            "style": "IPY_MODEL_4bb5de86119541599f75e79da9d02494",
            "value": "Batches: 100%"
          }
        },
        "59e4c7a4d84948d48788170718f0959b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b63e755ee9c4187ac68a7a48a0f9617",
            "max": 1097,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_179b1fa06cde4a3ea3596b7ea4520ad7",
            "value": 1097
          }
        },
        "acf25e94d46f46d4a8d6afc93b0d9a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f4b74e6f33a4ed087f67ef920634510",
            "placeholder": "​",
            "style": "IPY_MODEL_584de52dc9de467db3e62caae76258ed",
            "value": " 1097/1097 [03:29&lt;00:00, 30.42it/s]"
          }
        },
        "f4a8ddc39b484351bb99589ac6a24f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76344cea75a64c9487bda71d1ada3f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb5de86119541599f75e79da9d02494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b63e755ee9c4187ac68a7a48a0f9617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179b1fa06cde4a3ea3596b7ea4520ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f4b74e6f33a4ed087f67ef920634510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "584de52dc9de467db3e62caae76258ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c706aa55abc342c7abe6fa976f5b325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d02a3f0c1c3f4b5283d02cc5fb3f9658",
              "IPY_MODEL_d61c34e65b824b4d90b427d81ef9b343",
              "IPY_MODEL_bc723446db9b4b78ab7fad47851ccbb3"
            ],
            "layout": "IPY_MODEL_f01cde7aa80547069ed88daaf2510a2f"
          }
        },
        "d02a3f0c1c3f4b5283d02cc5fb3f9658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a3f2f72730440a9a558f323fc47b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_4817659ff2e94013be4d76cfe8558b85",
            "value": "Batches: 100%"
          }
        },
        "d61c34e65b824b4d90b427d81ef9b343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46abbb87aa5c4f6884582e0c4728b5ac",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19924670fdeb4a7d8c0568bd1653619b",
            "value": 301
          }
        },
        "bc723446db9b4b78ab7fad47851ccbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979b5a78310542f6ae7c2a6415f35eee",
            "placeholder": "​",
            "style": "IPY_MODEL_df36c68782894d2da3ae9ff0da84dc9f",
            "value": " 301/301 [01:01&lt;00:00, 45.75it/s]"
          }
        },
        "f01cde7aa80547069ed88daaf2510a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a3f2f72730440a9a558f323fc47b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4817659ff2e94013be4d76cfe8558b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46abbb87aa5c4f6884582e0c4728b5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19924670fdeb4a7d8c0568bd1653619b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "979b5a78310542f6ae7c2a6415f35eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df36c68782894d2da3ae9ff0da84dc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}